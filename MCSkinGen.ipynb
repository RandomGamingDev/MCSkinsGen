{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this block of code it will ask for your token from Hugging Face.\n",
        "\n",
        "If you don't have an account you can make one here: https://huggingface.co/join\n",
        "\n",
        "Before you can do this you need to accept the license agreement for the model, which you can do here: https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
        "\n",
        "On the token page select \"new token\" and ask for a \"read\" token (you can name it \"Colab\")."
      ],
      "metadata": {
        "id": "8pkEI3oVt_QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade accelerate==0.30.1 peft==0.11.1 transformers==4.41.1 diffusers==0.27.2 scipy==1.13.1 mediapy==1.2.0 networks==0.3.7 utils==1.0.2 pillow==10.3.0\n",
        "!git clone https://github.com/RandomGamingDev/MCSkinsGen\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "GR4vF2bw-sHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import peft\n",
        "import diffusers\n",
        "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler, StableDiffusionPipeline\n",
        "import mediapy as media\n",
        "import torch\n",
        "from torch import autocast\n",
        "from safetensors.torch import load_file\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "#@markdown Stable Diffusion Model\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "#@markdown The Device (this is mostly just for if you're running it on a different machine)\n",
        "device = \"cuda\" #@param {type:\"string\"}\n",
        "torch.set_default_device(device)\n",
        "\n",
        "scheduler = PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", skip_prk_steps=True, steps_offset=1)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None, use_auth_token=True).to(device)\n",
        "\n",
        "#@markdown LoRA Model\n",
        "lora_model = \"mcskins-18.safetensors\" #@param {type:\"string\"}\n",
        "\n",
        "pipe.load_lora_weights(f\"/content/MCSkinsGen/models/{ lora_model }\")\n",
        "\n",
        "# Skin Mask\n",
        "skin_mask = Image.open('/content/MCSkinsGen/skin_mask.png').convert(\"RGBA\")"
      ],
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is where you actually make images. Change the \"prompt\" to whatever you want to try and then change \"num_images\" if you want more than one image generated. You can re-run this cell without having to re-run everything before it."
      ],
      "metadata": {
        "id": "IoTE794luOXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Generation Parameters\n",
        "skin_name = \"WWI Infantry Soldier\" #@param {type:\"string\"}\n",
        "skin_category = \"people\" #@param [\"movies\", \"tv\", \"games\", \"people\", \"fantasy\", \"mobs\", \"others\"]\n",
        "skin_description = \"An infantry soldier from WWI\" #@param {type:\"string\"}\n",
        "prompt = f\"A { skin_name } minecraft skin in the { skin_category } category. { skin_description }\"\n",
        "num_images = 8 #@param {type:\"number\"}\n",
        "#@markdown (I recommend generating 8 images once you know what you want)\n",
        "\n",
        "prompts = [prompt] * num_images\n",
        "\n",
        "#@markdown AI Parameters\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#@markdown Recommended values: <br/>\n",
        "#@markdown - Most Recommended: `guidance_scale=7.5, num_inference_steps=50` <br/>\n",
        "#@markdown - `guidance_scale=15, num_inference_steps=50 or 100 or 200` <br/>\n",
        "#@markdown - `guidance_scale=30, num_inference_steps=100`\n",
        "\n",
        "with autocast(\"cuda\"):\n",
        "    images = pipe(prompts, guidance_scale=guidance_scale, num_inference_steps=num_inference_steps).images\n",
        "\n",
        "#@markdown To download the skins simply right click and press `Save As`\n",
        "mc_skin_size = (64, 64)\n",
        "images = [PIL.Image.composite(image.convert(\"RGBA\").resize(mc_skin_size, resample=PIL.Image.Resampling.NEAREST), PIL.Image.new(\"RGBA\", mc_skin_size), skin_mask) for image in images]\n",
        "media.show_images(images)"
      ],
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}